{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "djGFqrvK9u3d"
      },
      "outputs": [],
      "source": [
        "!pip install gradio --quiet\n",
        "! pip install snntorch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "from torch.utils.data import DataLoader\n",
        "from snntorch import surrogate\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import random_split\n",
        "from snntorch import functional as SF\n",
        "from snntorch import utils\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Additional Imports\n",
        "import snntorch as snn\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Video\n",
        "import gradio as gr\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "ZYrPJ6x797BR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "BETA = 0.5\n",
        "SPIKE_GRAD = surrogate.fast_sigmoid(slope=25)\n",
        "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "           \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "ICtt0JnuCIWH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, beta, spike_grad, num_steps):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 3, kernel_size = 5)\n",
        "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 5)\n",
        "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.fc1 = nn.Linear(16*4*4, 10)\n",
        "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.num_steps = num_steps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem_rec = []\n",
        "        spk_rec = []\n",
        "        batch_dim = int(x.shape[0])\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        for step in range(self.num_steps):\n",
        "            cur1 = F.max_pool2d(self.conv1(x), 2)\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            cur3 = self.fc1(spk2.view(batch_dim, 16*4*4))\n",
        "            spk_out, mem_out = self.lif3(cur3, mem3)\n",
        "            spk_rec.append(spk_out)\n",
        "            mem_rec.append(mem_out)\n",
        "\n",
        "        return torch.stack(spk_rec), torch.stack(mem_rec)"
      ],
      "metadata": {
        "id": "EKbixUZ__fQg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Classifier(beta = BETA, spike_grad = SPIKE_GRAD, num_steps = 50)\n",
        "classifier.load_state_dict(torch.load(\"./SNN_Model.pth\", map_location=torch.device(device)))\n",
        "classifier.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHgDtSAHCW4n",
        "outputId": "b1536c92-2991-43d6-e033-2f551ce33dc8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-38715f64818c>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  classifier.load_state_dict(torch.load(\"./SNN_Model.pth\", map_location=torch.device(device)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (lif1): Leaky()\n",
              "  (conv2): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (lif2): Leaky()\n",
              "  (fc1): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (lif3): Leaky()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.Grayscale(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0,), (1,))\n",
        "    ])\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "def process_model_output(model_output):\n",
        "    model_output_first_10 = model_output[:, :10, :]\n",
        "    activation_sums = torch.sum(model_output_first_10, dim=0)\n",
        "    most_activated_classes = torch.argmax(activation_sums, dim=1)\n",
        "    return most_activated_classes\n",
        "\n",
        "def predict(image):\n",
        "    image_tensor = preprocess_image(image)\n",
        "    with torch.no_grad():\n",
        "        output = classifier(image_tensor)\n",
        "        model_labels = process_model_output(output)\n",
        "    pred_label = model_labels[0] if model_labels[0] is not None else \"No Label\"\n",
        "    if pred_label == \"No Label\":\n",
        "        return \"No Label\"\n",
        "    return classes[pred_label]"
      ],
      "metadata": {
        "id": "QOiIuJLs_GCg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(fn=predict, inputs=\"image\", outputs=\"label\")\n",
        "interface.launch(share = True, debug = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjD9-ISGDlef",
        "outputId": "0ea56691-8923-4483-cb3e-c2b383fd3506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://8f55d0f8dae6a6c9f1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ]
    }
  ]
}