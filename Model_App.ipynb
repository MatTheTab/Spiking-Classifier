{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Spiking Neural Network for Image Classification"
      ],
      "metadata": {
        "id": "K-TzQpAjQDlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MatTheTab**: [Github](https://github.com/MatTheTab)\n",
        "\n",
        "This notebook is a live demo of a Spiking Neural Network for image classification. If you wish to turn on the demo all you need to do is to run this notebook and click the link at the bottom of the notebook - Gradio app link.\n",
        "\n",
        "If you have decided to retrain the model on your own then you will have to upload your own version of the model to the colab notebook and possibly change variables in the **Variables Declarations** to appropriate values."
      ],
      "metadata": {
        "id": "LoZJ2_vMQI4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "EVx4IhDMQJ4o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djGFqrvK9u3d",
        "outputId": "a883c300-370f-4969-f6ee-57cc0ae1a9ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m434.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gradio --quiet\n",
        "! pip install snntorch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/MatTheTab/Spiking-Classifier/raw/main/SNN_Model.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDsSaciuOFX3",
        "outputId": "70932bc9-6d17-4fcc-9880-e4d70e5ac50e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-28 13:47:13--  https://github.com/MatTheTab/Spiking-Classifier/raw/main/SNN_Model.pth\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MatTheTab/Spiking-Classifier/main/SNN_Model.pth [following]\n",
            "--2024-08-28 13:47:14--  https://raw.githubusercontent.com/MatTheTab/Spiking-Classifier/main/SNN_Model.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21324 (21K) [application/octet-stream]\n",
            "Saving to: ‘SNN_Model.pth’\n",
            "\n",
            "SNN_Model.pth       100%[===================>]  20.82K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-28 13:47:14 (74.0 MB/s) - ‘SNN_Model.pth’ saved [21324/21324]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "from torch.utils.data import DataLoader\n",
        "from snntorch import surrogate\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import random_split\n",
        "from snntorch import functional as SF\n",
        "from snntorch import utils\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Additional Imports\n",
        "import snntorch as snn\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Video\n",
        "import gradio as gr\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "ZYrPJ6x797BR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables Declarations"
      ],
      "metadata": {
        "id": "SdNqfvBEQMg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you decided to retrain the model from scratch with different values, then these values also need to be changed - you can still change them even if you are using a pretrained model but it might cause unexpected behaviour."
      ],
      "metadata": {
        "id": "j954ukEGfSJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "BETA = 0.5\n",
        "SPIKE_GRAD = surrogate.fast_sigmoid(slope=25)\n",
        "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "           \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "ICtt0JnuCIWH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "zpEBRwnHQRyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, beta, spike_grad, num_steps):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 3, kernel_size = 5)\n",
        "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 5)\n",
        "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.fc1 = nn.Linear(16*4*4, 10)\n",
        "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.num_steps = num_steps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem_rec = []\n",
        "        spk_rec = []\n",
        "        batch_dim = int(x.shape[0])\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        for step in range(self.num_steps):\n",
        "            cur1 = F.max_pool2d(self.conv1(x), 2)\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            cur3 = self.fc1(spk2.view(batch_dim, 16*4*4))\n",
        "            spk_out, mem_out = self.lif3(cur3, mem3)\n",
        "            spk_rec.append(spk_out)\n",
        "            mem_rec.append(mem_out)\n",
        "\n",
        "        return torch.stack(spk_rec), torch.stack(mem_rec)"
      ],
      "metadata": {
        "id": "EKbixUZ__fQg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Classifier(beta = BETA, spike_grad = SPIKE_GRAD, num_steps = 50)\n",
        "classifier.load_state_dict(torch.load(\"./SNN_Model.pth\", map_location=torch.device(device)))\n",
        "classifier.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHgDtSAHCW4n",
        "outputId": "96abd840-d402-4d1c-cfcd-ff95380aa36a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-38715f64818c>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  classifier.load_state_dict(torch.load(\"./SNN_Model.pth\", map_location=torch.device(device)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (lif1): Leaky()\n",
              "  (conv2): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (lif2): Leaky()\n",
              "  (fc1): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (lif3): Leaky()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio App"
      ],
      "metadata": {
        "id": "tMVZMtugQTrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.Grayscale(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0,), (1,))\n",
        "    ])\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "def process_model_output(model_output):\n",
        "    model_output_first_10 = model_output[:, :10, :]\n",
        "    activation_sums = torch.sum(model_output_first_10, dim=0)\n",
        "    most_activated_classes = torch.argmax(activation_sums, dim=1)\n",
        "    return most_activated_classes\n",
        "\n",
        "def predict(image):\n",
        "    image_tensor = preprocess_image(image)\n",
        "    with torch.no_grad():\n",
        "        output = classifier(image_tensor)\n",
        "        model_labels = process_model_output(output)\n",
        "    pred_label = model_labels[0] if model_labels[0] is not None else \"No Label\"\n",
        "    if pred_label == \"No Label\":\n",
        "        return \"No Label\"\n",
        "    return classes[pred_label]"
      ],
      "metadata": {
        "id": "QOiIuJLs_GCg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(fn=predict, inputs=\"image\", outputs=\"label\")\n",
        "interface.launch(share = True, debug = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjD9-ISGDlef",
        "outputId": "254f1931-e80c-4736-99aa-9c8ca132232b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://de1fc973b0a5bd2a7d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ]
    }
  ]
}