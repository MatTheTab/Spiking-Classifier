{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Spiking Neural Network for Image Classification"
      ],
      "metadata": {
        "id": "K-TzQpAjQDlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MatTheTab**: [Github](https://github.com/MatTheTab)\n",
        "\n",
        "This notebook is a live demo of a Spiking Neural Network for image classification. If you wish to turn on the demo all you need to do is to run this notebook and click the link at the bottom of the notebook - Gradio app link.\n",
        "\n",
        "If you have decided to retrain the model on your own then you will have to upload your own version of the model to the colab notebook and possibly change variables in the **Variables Declarations** to appropriate values."
      ],
      "metadata": {
        "id": "LoZJ2_vMQI4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "EVx4IhDMQJ4o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djGFqrvK9u3d",
        "outputId": "4636789a-9397-4711-934a-8fb4ebdcb999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m337.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gradio --quiet\n",
        "! pip install snntorch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/MatTheTab/Spiking-Classifier/raw/main/SNN_Model.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDsSaciuOFX3",
        "outputId": "f914cda7-79ec-46ba-b4a1-3cb1bc1cc4c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-30 16:33:53--  https://github.com/MatTheTab/Spiking-Classifier/raw/main/SNN_Model.pth\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MatTheTab/Spiking-Classifier/main/SNN_Model.pth [following]\n",
            "--2024-08-30 16:33:53--  https://raw.githubusercontent.com/MatTheTab/Spiking-Classifier/main/SNN_Model.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94220 (92K) [application/octet-stream]\n",
            "Saving to: ‘SNN_Model.pth’\n",
            "\n",
            "SNN_Model.pth       100%[===================>]  92.01K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-08-30 16:33:53 (3.79 MB/s) - ‘SNN_Model.pth’ saved [94220/94220]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "from torch.utils.data import DataLoader\n",
        "from snntorch import surrogate\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import random_split\n",
        "from snntorch import functional as SF\n",
        "from snntorch import utils\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Additional Imports\n",
        "import snntorch as snn\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Video\n",
        "import gradio as gr\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "ZYrPJ6x797BR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables Declarations"
      ],
      "metadata": {
        "id": "SdNqfvBEQMg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you decided to retrain the model from scratch with different values, then these values also need to be changed - you can still change them even if you are using a pretrained model but it might cause unexpected behaviour."
      ],
      "metadata": {
        "id": "j954ukEGfSJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "BETA = 0.5\n",
        "SPIKE_GRAD = surrogate.fast_sigmoid(slope=25)\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "metadata": {
        "id": "ICtt0JnuCIWH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "zpEBRwnHQRyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, beta, spike_grad, num_steps):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5)\n",
        "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5)\n",
        "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 10)\n",
        "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.num_steps = num_steps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem_rec = []\n",
        "        spk_rec = []\n",
        "        batch_dim = int(x.shape[0])\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        for step in range(self.num_steps):\n",
        "            cur1 = F.max_pool2d(self.conv1(x), 2)\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            cur3 = self.fc1(spk2.view(batch_dim, 32*5*5))\n",
        "            spk_out, mem_out = self.lif3(cur3, mem3)\n",
        "            spk_rec.append(spk_out)\n",
        "            mem_rec.append(mem_out)\n",
        "\n",
        "        return torch.stack(spk_rec), torch.stack(mem_rec)"
      ],
      "metadata": {
        "id": "EKbixUZ__fQg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Classifier(beta = BETA, spike_grad = SPIKE_GRAD, num_steps = 50)\n",
        "classifier.load_state_dict(torch.load(\"./SNN_Model.pth\", map_location=torch.device(device), weights_only=True))\n",
        "classifier.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHgDtSAHCW4n",
        "outputId": "cd58c840-3d0c-48be-f8d0-f1b790bd35a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (lif1): Leaky()\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (lif2): Leaky()\n",
              "  (fc1): Linear(in_features=800, out_features=10, bias=True)\n",
              "  (lif3): Leaky()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio App"
      ],
      "metadata": {
        "id": "tMVZMtugQTrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below app will be launched using Gradio, all you need to do after running the notebook is to click the link produced below the code cell. You can test the model's performance by uploading your own photos, but they should be related to the CIFAR 10 dataset (or if you decided to retrain the model, the new relevant dataset). Currently supported classes include:\n",
        "\n",
        "[\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "metadata": {
        "id": "tsnKuadV_OUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "def process_model_output(model_output):\n",
        "    model_output_first_10 = model_output[:, :10, :]\n",
        "    activation_sums = torch.sum(model_output_first_10, dim=0)\n",
        "    most_activated_classes = torch.argmax(activation_sums, dim=1)\n",
        "    return most_activated_classes\n",
        "\n",
        "def predict(image):\n",
        "    image_tensor = preprocess_image(image)\n",
        "    with torch.no_grad():\n",
        "        output, _ = classifier(image_tensor)\n",
        "        model_labels = process_model_output(output)\n",
        "    pred_label = model_labels[0] if model_labels[0] is not None else \"No Label\"\n",
        "    if pred_label == \"No Label\":\n",
        "        return \"No Label\"\n",
        "    return classes[pred_label]"
      ],
      "metadata": {
        "id": "QOiIuJLs_GCg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(fn=predict, inputs=\"image\", outputs=\"label\")\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "tjD9-ISGDlef",
        "outputId": "181bde15-1764-4336-9f36-9b25651d9460"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://821161014aff9541b2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://821161014aff9541b2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}